Loaded module: cuda/12.3.2
Loaded module: cudnn/v8.9.7.29-prod-cuda-12.X
2024-05-21 15:42:12.222534: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-21 15:42:12.276401: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-21 15:42:13.524390: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
  0%|          | 0/1185 [00:00<?, ?it/s]  2%|▏         | 21/1185 [00:00<00:05, 201.31it/s]  4%|▎         | 42/1185 [00:00<00:05, 202.33it/s]  5%|▌         | 63/1185 [00:00<00:05, 203.22it/s]  7%|▋         | 84/1185 [00:00<00:05, 202.98it/s]  9%|▉         | 105/1185 [00:00<00:05, 204.66it/s] 11%|█         | 126/1185 [00:00<00:05, 204.75it/s] 12%|█▏        | 147/1185 [00:00<00:05, 205.97it/s] 14%|█▍        | 168/1185 [00:00<00:04, 206.28it/s] 16%|█▌        | 189/1185 [00:00<00:04, 206.52it/s] 18%|█▊        | 210/1185 [00:01<00:04, 204.83it/s] 19%|█▉        | 231/1185 [00:01<00:04, 205.25it/s] 21%|██▏       | 252/1185 [00:01<00:04, 205.17it/s] 23%|██▎       | 273/1185 [00:01<00:04, 206.01it/s] 25%|██▍       | 294/1185 [00:01<00:04, 203.36it/s] 27%|██▋       | 315/1185 [00:01<00:04, 203.27it/s] 28%|██▊       | 336/1185 [00:01<00:04, 204.11it/s] 30%|███       | 357/1185 [00:01<00:04, 204.23it/s] 32%|███▏      | 379/1185 [00:01<00:03, 205.76it/s] 34%|███▍      | 400/1185 [00:01<00:03, 206.25it/s] 36%|███▌      | 421/1185 [00:02<00:03, 206.63it/s] 37%|███▋      | 442/1185 [00:02<00:03, 206.53it/s] 39%|███▉      | 463/1185 [00:02<00:03, 206.69it/s] 41%|████      | 485/1185 [00:02<00:03, 207.54it/s] 43%|████▎     | 506/1185 [00:02<00:03, 207.51it/s] 44%|████▍     | 527/1185 [00:02<00:03, 208.15it/s] 46%|████▌     | 548/1185 [00:02<00:03, 207.85it/s] 48%|████▊     | 569/1185 [00:02<00:02, 207.95it/s] 50%|████▉     | 590/1185 [00:02<00:02, 207.16it/s] 52%|█████▏    | 612/1185 [00:02<00:02, 208.35it/s] 53%|█████▎    | 633/1185 [00:03<00:02, 208.16it/s] 55%|█████▌    | 654/1185 [00:03<00:02, 207.51it/s] 57%|█████▋    | 675/1185 [00:03<00:02, 208.11it/s] 59%|█████▊    | 696/1185 [00:03<00:02, 208.28it/s] 61%|██████    | 717/1185 [00:03<00:02, 206.29it/s] 62%|██████▏   | 738/1185 [00:03<00:02, 206.43it/s] 64%|██████▍   | 759/1185 [00:03<00:02, 206.45it/s] 66%|██████▌   | 780/1185 [00:03<00:01, 206.94it/s] 68%|██████▊   | 801/1185 [00:03<00:01, 206.13it/s] 69%|██████▉   | 822/1185 [00:03<00:01, 206.98it/s] 71%|███████   | 843/1185 [00:04<00:01, 206.90it/s] 73%|███████▎  | 864/1185 [00:04<00:01, 206.91it/s] 75%|███████▍  | 885/1185 [00:04<00:01, 206.92it/s] 76%|███████▋  | 906/1185 [00:04<00:01, 206.83it/s] 78%|███████▊  | 927/1185 [00:04<00:01, 206.34it/s] 80%|████████  | 948/1185 [00:04<00:01, 206.73it/s] 82%|████████▏ | 969/1185 [00:04<00:01, 205.54it/s] 84%|████████▎ | 990/1185 [00:04<00:00, 206.43it/s] 85%|████████▌ | 1011/1185 [00:04<00:00, 206.61it/s] 87%|████████▋ | 1033/1185 [00:05<00:00, 208.49it/s] 89%|████████▉ | 1054/1185 [00:05<00:00, 208.48it/s] 91%|█████████ | 1075/1185 [00:05<00:00, 208.80it/s] 92%|█████████▏| 1096/1185 [00:05<00:00, 208.58it/s] 94%|█████████▍| 1118/1185 [00:05<00:00, 206.73it/s] 96%|█████████▌| 1140/1185 [00:05<00:00, 207.62it/s] 98%|█████████▊| 1162/1185 [00:05<00:00, 207.99it/s]100%|█████████▉| 1184/1185 [00:05<00:00, 208.91it/s]100%|██████████| 1185/1185 [00:05<00:00, 206.62it/s]
2024-05-21 15:42:24.172920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78738 MB memory:  -> device: 0, name: NVIDIA H100 PCIe, pci bus id: 0000:41:00.0, compute capability: 9.0
  0%|          | 0/509 [00:00<?, ?it/s]  4%|▍         | 20/509 [00:00<00:02, 198.37it/s]  8%|▊         | 41/509 [00:00<00:02, 204.95it/s] 12%|█▏        | 62/509 [00:00<00:02, 206.21it/s] 16%|█▋        | 83/509 [00:00<00:02, 205.41it/s] 20%|██        | 104/509 [00:00<00:01, 206.79it/s] 25%|██▍       | 125/509 [00:00<00:01, 207.62it/s] 29%|██▉       | 147/509 [00:00<00:01, 208.70it/s] 33%|███▎      | 169/509 [00:00<00:01, 208.98it/s] 37%|███▋      | 190/509 [00:00<00:01, 209.09it/s] 41%|████▏     | 211/509 [00:01<00:01, 208.17it/s] 46%|████▌     | 233/509 [00:01<00:01, 209.95it/s] 50%|████▉     | 254/509 [00:01<00:01, 209.84it/s] 54%|█████▍    | 275/509 [00:01<00:01, 209.88it/s] 58%|█████▊    | 297/509 [00:01<00:01, 209.84it/s] 63%|██████▎   | 319/509 [00:01<00:00, 209.66it/s] 67%|██████▋   | 341/509 [00:01<00:00, 210.27it/s] 71%|███████▏  | 363/509 [00:01<00:00, 210.81it/s] 76%|███████▌  | 385/509 [00:01<00:00, 210.50it/s] 80%|███████▉  | 407/509 [00:01<00:00, 209.87it/s] 84%|████████▍ | 429/509 [00:02<00:00, 210.35it/s] 89%|████████▊ | 451/509 [00:02<00:00, 210.26it/s] 93%|█████████▎| 473/509 [00:02<00:00, 209.51it/s] 97%|█████████▋| 494/509 [00:02<00:00, 208.41it/s]100%|██████████| 509/509 [00:02<00:00, 208.81it/s]
  0%|          | 0/8973 [00:00<?, ?it/s]  0%|          | 19/8973 [00:00<00:48, 185.26it/s]  0%|          | 38/8973 [00:00<00:48, 182.46it/s]  1%|          | 57/8973 [00:00<00:52, 170.80it/s]  1%|          | 76/8973 [00:00<00:50, 176.98it/s]  1%|          | 95/8973 [00:00<00:49, 180.38it/s]  1%|▏         | 114/8973 [00:00<00:50, 177.06it/s]  1%|▏         | 133/8973 [00:00<00:49, 179.87it/s]  2%|▏         | 152/8973 [00:00<00:48, 182.73it/s]  2%|▏         | 171/8973 [00:00<00:47, 184.17it/s]  2%|▏         | 191/8973 [00:01<00:47, 186.34it/s]  2%|▏         | 210/8973 [00:01<00:47, 185.84it/s]  3%|▎         | 229/8973 [00:01<00:47, 185.83it/s]  3%|▎         | 248/8973 [00:01<00:46, 186.06it/s]  3%|▎         | 267/8973 [00:01<00:46, 186.39it/s]  3%|▎         | 286/8973 [00:01<00:46, 185.19it/s]  3%|▎         | 305/8973 [00:01<00:46, 185.61it/s]  4%|▎         | 324/8973 [00:01<00:46, 184.89it/s]  4%|▍         | 343/8973 [00:01<00:46, 185.76it/s]  4%|▍         | 362/8973 [00:01<00:46, 185.36it/s]  4%|▍         | 381/8973 [00:02<00:46, 186.64it/s]  4%|▍         | 400/8973 [00:02<00:46, 185.80it/s]  5%|▍         | 419/8973 [00:02<00:46, 185.61it/s]  5%|▍         | 438/8973 [00:02<00:46, 184.82it/s]  5%|▌         | 458/8973 [00:02<00:45, 186.60it/s]  5%|▌         | 477/8973 [00:02<00:45, 186.92it/s]  6%|▌         | 497/8973 [00:02<00:45, 188.26it/s]  6%|▌         | 516/8973 [00:02<00:45, 187.79it/s]  6%|▌         | 535/8973 [00:02<00:44, 188.34it/s]  6%|▌         | 554/8973 [00:02<00:44, 188.49it/s]  6%|▋         | 573/8973 [00:03<00:44, 187.85it/s]  7%|▋         | 592/8973 [00:03<00:44, 187.36it/s]  7%|▋         | 612/8973 [00:03<00:44, 188.14it/s]  7%|▋         | 632/8973 [00:03<00:44, 188.62it/s]  7%|▋         | 651/8973 [00:03<00:44, 188.44it/s]  7%|▋         | 670/8973 [00:03<00:44, 187.65it/s]  8%|▊         | 690/8973 [00:03<00:44, 188.24it/s]  8%|▊         | 709/8973 [00:03<00:43, 188.02it/s]  8%|▊         | 728/8973 [00:03<00:43, 188.11it/s]  8%|▊         | 747/8973 [00:04<00:43, 187.09it/s]  9%|▊         | 766/8973 [00:04<00:43, 187.37it/s]  9%|▊         | 785/8973 [00:04<00:43, 187.38it/s]  9%|▉         | 804/8973 [00:04<00:43, 187.08it/s]  9%|▉         | 823/8973 [00:04<00:43, 187.73it/s]  9%|▉         | 842/8973 [00:04<00:43, 187.49it/s] 10%|▉         | 862/8973 [00:04<00:42, 188.90it/s] 10%|▉         | 882/8973 [00:04<00:42, 189.02it/s] 10%|█         | 902/8973 [00:04<00:42, 189.00it/s] 10%|█         | 922/8973 [00:04<00:42, 189.11it/s] 10%|█         | 941/8973 [00:05<00:42, 188.96it/s] 11%|█         | 960/8973 [00:05<00:42, 188.30it/s] 11%|█         | 979/8973 [00:05<00:42, 187.86it/s] 11%|█         | 998/8973 [00:05<00:42, 187.71it/s] 11%|█▏        | 1018/8973 [00:05<00:42, 188.72it/s] 12%|█▏        | 1037/8973 [00:05<00:42, 188.66it/s] 12%|█▏        | 1056/8973 [00:05<00:42, 188.06it/s] 12%|█▏        | 1076/8973 [00:05<00:41, 188.66it/s] 12%|█▏        | 1096/8973 [00:05<00:41, 189.32it/s] 12%|█▏        | 1115/8973 [00:05<00:41, 188.70it/s] 13%|█▎        | 1134/8973 [00:06<00:41, 188.91it/s] 13%|█▎        | 1153/8973 [00:06<00:41, 188.30it/s] 13%|█▎        | 1172/8973 [00:06<00:41, 187.62it/s] 13%|█▎        | 1191/8973 [00:06<00:41, 187.97it/s] 13%|█▎        | 1210/8973 [00:06<00:41, 187.78it/s] 14%|█▎        | 1230/8973 [00:06<00:41, 188.82it/s] 14%|█▍        | 1249/8973 [00:06<00:41, 187.52it/s] 14%|█▍        | 1268/8973 [00:06<00:41, 187.43it/s] 14%|█▍        | 1287/8973 [00:06<00:40, 188.02it/s] 15%|█▍        | 1306/8973 [00:06<00:40, 187.18it/s] 15%|█▍        | 1325/8973 [00:07<00:40, 187.14it/s] 15%|█▍        | 1344/8973 [00:07<00:40, 186.49it/s] 15%|█▌        | 1364/8973 [00:07<00:40, 187.24it/s] 15%|█▌        | 1384/8973 [00:07<00:40, 188.04it/s] 16%|█▌        | 1403/8973 [00:07<00:40, 187.16it/s] 16%|█▌        | 1422/8973 [00:07<00:40, 186.50it/s] 16%|█▌        | 1441/8973 [00:07<00:40, 186.42it/s] 16%|█▋        | 1460/8973 [00:07<00:40, 186.33it/s] 16%|█▋        | 1479/8973 [00:07<00:40, 186.61it/s] 17%|█▋        | 1498/8973 [00:08<00:40, 186.11it/s] 17%|█▋        | 1517/8973 [00:08<00:40, 185.97it/s] 17%|█▋        | 1536/8973 [00:08<00:40, 185.53it/s] 17%|█▋        | 1555/8973 [00:08<00:39, 186.16it/s] 18%|█▊        | 1574/8973 [00:08<00:39, 185.06it/s] 18%|█▊        | 1593/8973 [00:08<00:39, 184.51it/s] 18%|█▊        | 1612/8973 [00:08<00:39, 184.34it/s] 18%|█▊        | 1631/8973 [00:08<00:39, 184.97it/s] 18%|█▊        | 1650/8973 [00:08<00:39, 184.79it/s] 19%|█▊        | 1669/8973 [00:08<00:39, 184.91it/s] 19%|█▉        | 1688/8973 [00:09<00:39, 184.77it/s] 19%|█▉        | 1707/8973 [00:09<00:39, 185.15it/s] 19%|█▉        | 1726/8973 [00:09<00:39, 184.88it/s] 19%|█▉        | 1745/8973 [00:09<00:38, 186.03it/s] 20%|█▉        | 1764/8973 [00:09<00:38, 186.67it/s] 20%|█▉        | 1783/8973 [00:09<00:38, 186.70it/s] 20%|██        | 1802/8973 [00:09<00:38, 186.90it/s] 20%|██        | 1821/8973 [00:09<00:38, 186.86it/s] 21%|██        | 1840/8973 [00:09<00:38, 186.81it/s] 21%|██        | 1859/8973 [00:09<00:38, 187.13it/s] 21%|██        | 1878/8973 [00:10<00:38, 186.26it/s] 21%|██        | 1897/8973 [00:10<00:38, 186.20it/s] 21%|██▏       | 1916/8973 [00:10<00:38, 185.52it/s] 22%|██▏       | 1935/8973 [00:10<00:37, 186.18it/s] 22%|██▏       | 1954/8973 [00:10<00:38, 184.69it/s] 22%|██▏       | 1973/8973 [00:10<00:37, 185.21it/s] 22%|██▏       | 1992/8973 [00:10<00:37, 184.96it/s] 22%|██▏       | 2011/8973 [00:10<00:37, 185.83it/s] 23%|██▎       | 2030/8973 [00:10<00:37, 185.21it/s] 23%|██▎       | 2049/8973 [00:10<00:37, 185.85it/s] 23%|██▎       | 2068/8973 [00:11<00:37, 184.85it/s] 23%|██▎       | 2087/8973 [00:11<00:37, 185.12it/s] 23%|██▎       | 2106/8973 [00:11<00:37, 185.00it/s] 24%|██▎       | 2125/8973 [00:11<00:37, 184.84it/s] 24%|██▍       | 2144/8973 [00:11<00:36, 185.02it/s] 24%|██▍       | 2163/8973 [00:11<00:36, 184.92it/s] 24%|██▍       | 2182/8973 [00:11<00:36, 185.23it/s] 25%|██▍       | 2201/8973 [00:11<00:36, 185.70it/s] 25%|██▍       | 2220/8973 [00:11<00:36, 185.55it/s] 25%|██▍       | 2239/8973 [00:12<00:36, 185.14it/s] 25%|██▌       | 2258/8973 [00:12<00:36, 184.61it/s] 25%|██▌       | 2277/8973 [00:12<00:36, 185.58it/s] 26%|██▌       | 2296/8973 [00:12<00:36, 185.05it/s] 26%|██▌       | 2315/8973 [00:12<00:35, 185.92it/s] 26%|██▌       | 2334/8973 [00:12<00:35, 186.56it/s] 26%|██▌       | 2353/8973 [00:12<00:35, 187.30it/s] 26%|██▋       | 2372/8973 [00:12<00:35, 187.22it/s] 27%|██▋       | 2391/8973 [00:12<00:35, 187.01it/s] 27%|██▋       | 2410/8973 [00:12<00:35, 186.13it/s] 27%|██▋       | 2429/8973 [00:13<00:35, 185.09it/s] 27%|██▋       | 2448/8973 [00:13<00:35, 185.21it/s] 27%|██▋       | 2467/8973 [00:13<00:34, 186.10it/s] 28%|██▊       | 2486/8973 [00:13<00:34, 185.73it/s] 28%|██▊       | 2505/8973 [00:13<00:34, 186.83it/s] 28%|██▊       | 2524/8973 [00:13<00:34, 186.52it/s] 28%|██▊       | 2543/8973 [00:13<00:34, 187.12it/s] 29%|██▊       | 2562/8973 [00:13<00:34, 186.96it/s] 29%|██▉       | 2581/8973 [00:13<00:34, 186.68it/s] 29%|██▉       | 2600/8973 [00:13<00:34, 185.59it/s] 29%|██▉       | 2619/8973 [00:14<00:34, 186.23it/s] 29%|██▉       | 2638/8973 [00:14<00:34, 185.66it/s] 30%|██▉       | 2657/8973 [00:14<00:33, 185.78it/s] 30%|██▉       | 2676/8973 [00:14<00:33, 185.79it/s] 30%|███       | 2696/8973 [00:14<00:33, 187.65it/s] 30%|███       | 2715/8973 [00:14<00:33, 187.42it/s] 30%|███       | 2734/8973 [00:14<00:33, 187.80it/s] 31%|███       | 2754/8973 [00:14<00:32, 188.56it/s] 31%|███       | 2774/8973 [00:14<00:32, 190.37it/s] 31%|███       | 2794/8973 [00:14<00:32, 190.84it/s] 31%|███▏      | 2814/8973 [00:15<00:32, 189.88it/s] 32%|███▏      | 2833/8973 [00:15<00:32, 189.14it/s] 32%|███▏      | 2853/8973 [00:15<00:32, 189.53it/s] 32%|███▏      | 2873/8973 [00:15<00:31, 191.19it/s] 32%|███▏      | 2893/8973 [00:15<00:31, 190.38it/s] 32%|███▏      | 2913/8973 [00:15<00:31, 189.73it/s] 33%|███▎      | 2932/8973 [00:15<00:31, 189.78it/s] 33%|███▎      | 2951/8973 [00:15<00:31, 189.69it/s] 33%|███▎      | 2970/8973 [00:15<00:31, 188.81it/s] 33%|███▎      | 2990/8973 [00:16<00:31, 189.75it/s] 34%|███▎      | 3010/8973 [00:16<00:31, 190.23it/s] 34%|███▍      | 3030/8973 [00:16<00:31, 189.68it/s] 34%|███▍      | 3050/8973 [00:16<00:31, 190.51it/s] 34%|███▍      | 3070/8973 [00:16<00:30, 191.33it/s] 34%|███▍      | 3090/8973 [00:16<00:31, 189.26it/s] 35%|███▍      | 3110/8973 [00:16<00:30, 189.89it/s] 35%|███▍      | 3129/8973 [00:16<00:34, 171.88it/s] 35%|███▌      | 3147/8973 [00:16<00:33, 172.33it/s] 35%|███▌      | 3167/8973 [00:16<00:33, 175.92it/s] 35%|███▌      | 3185/8973 [00:17<00:32, 176.62it/s] 36%|███▌      | 3204/8973 [00:17<00:32, 179.17it/s] 36%|███▌      | 3223/8973 [00:17<00:31, 181.84it/s] 36%|███▌      | 3242/8973 [00:17<00:31, 183.57it/s] 36%|███▋      | 3261/8973 [00:17<00:30, 184.85it/s] 37%|███▋      | 3280/8973 [00:17<00:30, 186.09it/s] 37%|███▋      | 3300/8973 [00:17<00:30, 187.69it/s] 37%|███▋      | 3320/8973 [00:17<00:29, 188.67it/s] 37%|███▋      | 3339/8973 [00:17<00:29, 188.55it/s] 37%|███▋      | 3358/8973 [00:18<00:29, 188.65it/s] 38%|███▊      | 3377/8973 [00:18<00:29, 189.04it/s] 38%|███▊      | 3396/8973 [00:18<00:29, 188.74it/s] 38%|███▊      | 3416/8973 [00:18<00:29, 189.31it/s] 38%|███▊      | 3435/8973 [00:18<00:29, 188.04it/s] 38%|███▊      | 3454/8973 [00:18<00:29, 188.06it/s] 39%|███▊      | 3473/8973 [00:18<00:29, 188.42it/s] 39%|███▉      | 3493/8973 [00:18<00:28, 189.00it/s] 39%|███▉      | 3513/8973 [00:18<00:28, 189.40it/s] 39%|███▉      | 3532/8973 [00:18<00:28, 188.53it/s] 40%|███▉      | 3552/8973 [00:19<00:28, 189.96it/s] 40%|███▉      | 3571/8973 [00:19<00:28, 189.76it/s] 40%|████      | 3591/8973 [00:19<00:28, 190.14it/s] 40%|████      | 3611/8973 [00:19<00:28, 189.96it/s] 40%|████      | 3630/8973 [00:19<00:28, 189.68it/s] 41%|████      | 3650/8973 [00:19<00:27, 190.64it/s] 41%|████      | 3670/8973 [00:19<00:27, 190.31it/s] 41%|████      | 3690/8973 [00:19<00:27, 189.46it/s] 41%|████▏     | 3709/8973 [00:19<00:27, 189.57it/s] 42%|████▏     | 3729/8973 [00:19<00:27, 189.69it/s] 42%|████▏     | 3748/8973 [00:20<00:27, 189.07it/s] 42%|████▏     | 3767/8973 [00:20<00:27, 188.50it/s] 42%|████▏     | 3786/8973 [00:20<00:27, 188.53it/s] 42%|████▏     | 3805/8973 [00:20<00:27, 188.30it/s] 43%|████▎     | 3824/8973 [00:20<00:27, 187.94it/s] 43%|████▎     | 3844/8973 [00:20<00:27, 188.48it/s] 43%|████▎     | 3863/8973 [00:20<00:27, 188.10it/s] 43%|████▎     | 3882/8973 [00:20<00:26, 188.60it/s] 43%|████▎     | 3901/8973 [00:20<00:27, 187.84it/s] 44%|████▎     | 3921/8973 [00:20<00:26, 189.64it/s] 44%|████▍     | 3940/8973 [00:21<00:26, 188.80it/s] 44%|████▍     | 3960/8973 [00:21<00:26, 190.01it/s] 44%|████▍     | 3979/8973 [00:21<00:26, 188.97it/s] 45%|████▍     | 3999/8973 [00:21<00:26, 190.31it/s] 45%|████▍     | 4019/8973 [00:21<00:26, 190.50it/s] 45%|████▌     | 4039/8973 [00:21<00:25, 190.08it/s] 45%|████▌     | 4059/8973 [00:21<00:25, 190.85it/s] 45%|████▌     | 4079/8973 [00:21<00:25, 189.97it/s] 46%|████▌     | 4098/8973 [00:21<00:25, 188.64it/s] 46%|████▌     | 4117/8973 [00:22<00:25, 187.98it/s] 46%|████▌     | 4136/8973 [00:22<00:25, 186.78it/s] 46%|████▋     | 4155/8973 [00:22<00:25, 186.65it/s] 47%|████▋     | 4175/8973 [00:22<00:25, 188.56it/s] 47%|████▋     | 4194/8973 [00:22<00:25, 188.30it/s] 47%|████▋     | 4213/8973 [00:22<00:25, 188.62it/s] 47%|████▋     | 4232/8973 [00:22<00:25, 188.38it/s] 47%|████▋     | 4251/8973 [00:22<00:25, 188.63it/s] 48%|████▊     | 4270/8973 [00:22<00:24, 188.61it/s] 48%|████▊     | 4289/8973 [00:22<00:24, 188.11it/s] 48%|████▊     | 4309/8973 [00:23<00:24, 189.35it/s] 48%|████▊     | 4328/8973 [00:23<00:24, 188.77it/s] 48%|████▊     | 4347/8973 [00:23<00:24, 188.89it/s] 49%|████▊     | 4366/8973 [00:23<00:24, 188.34it/s] 49%|████▉     | 4385/8973 [00:23<00:24, 188.00it/s] 49%|████▉     | 4404/8973 [00:23<00:24, 187.47it/s] 49%|████▉     | 4424/8973 [00:23<00:24, 189.41it/s] 50%|████▉     | 4443/8973 [00:23<00:23, 188.93it/s] 50%|████▉     | 4462/8973 [00:23<00:23, 188.64it/s] 50%|████▉     | 4481/8973 [00:23<00:23, 188.58it/s] 50%|█████     | 4500/8973 [00:24<00:23, 187.85it/s] 50%|█████     | 4519/8973 [00:24<00:23, 188.44it/s] 51%|█████     | 4539/8973 [00:24<00:23, 189.49it/s] 51%|█████     | 4559/8973 [00:24<00:23, 190.13it/s] 51%|█████     | 4579/8973 [00:24<00:23, 188.90it/s] 51%|█████     | 4598/8973 [00:24<00:23, 189.19it/s] 51%|█████▏    | 4618/8973 [00:24<00:22, 189.45it/s] 52%|█████▏    | 4638/8973 [00:24<00:22, 189.80it/s] 52%|█████▏    | 4657/8973 [00:24<00:22, 189.65it/s] 52%|█████▏    | 4676/8973 [00:24<00:22, 189.62it/s] 52%|█████▏    | 4695/8973 [00:25<00:22, 187.87it/s] 53%|█████▎    | 4714/8973 [00:25<00:22, 186.64it/s] 53%|█████▎    | 4733/8973 [00:25<00:22, 185.75it/s] 53%|█████▎    | 4752/8973 [00:25<00:22, 186.38it/s] 53%|█████▎    | 4771/8973 [00:25<00:22, 185.57it/s] 53%|█████▎    | 4790/8973 [00:25<00:22, 186.35it/s] 54%|█████▎    | 4809/8973 [00:25<00:22, 186.55it/s] 54%|█████▍    | 4828/8973 [00:25<00:22, 187.13it/s] 54%|█████▍    | 4847/8973 [00:25<00:22, 186.17it/s] 54%|█████▍    | 4866/8973 [00:26<00:22, 185.60it/s] 54%|█████▍    | 4885/8973 [00:26<00:21, 186.64it/s] 55%|█████▍    | 4905/8973 [00:26<00:21, 187.42it/s] 55%|█████▍    | 4925/8973 [00:26<00:21, 188.52it/s] 55%|█████▌    | 4945/8973 [00:26<00:21, 189.51it/s] 55%|█████▌    | 4964/8973 [00:26<00:21, 189.10it/s] 56%|█████▌    | 4983/8973 [00:26<00:21, 188.76it/s] 56%|█████▌    | 5003/8973 [00:26<00:20, 189.25it/s] 56%|█████▌    | 5023/8973 [00:26<00:20, 190.06it/s] 56%|█████▌    | 5043/8973 [00:26<00:20, 188.84it/s] 56%|█████▋    | 5063/8973 [00:27<00:20, 189.69it/s] 57%|█████▋    | 5083/8973 [00:27<00:20, 190.53it/s] 57%|█████▋    | 5103/8973 [00:27<00:20, 190.26it/s] 57%|█████▋    | 5123/8973 [00:27<00:20, 190.63it/s] 57%|█████▋    | 5143/8973 [00:27<00:20, 189.72it/s] 58%|█████▊    | 5162/8973 [00:27<00:20, 189.47it/s] 58%|█████▊    | 5181/8973 [00:27<00:20, 189.33it/s] 58%|█████▊    | 5200/8973 [00:27<00:19, 189.05it/s] 58%|█████▊    | 5220/8973 [00:27<00:19, 189.95it/s] 58%|█████▊    | 5239/8973 [00:27<00:19, 189.55it/s] 59%|█████▊    | 5258/8973 [00:28<00:19, 188.98it/s] 59%|█████▉    | 5278/8973 [00:28<00:19, 189.68it/s] 59%|█████▉    | 5297/8973 [00:28<00:19, 189.73it/s] 59%|█████▉    | 5317/8973 [00:28<00:19, 190.03it/s] 59%|█████▉    | 5337/8973 [00:28<00:19, 188.88it/s] 60%|█████▉    | 5356/8973 [00:28<00:19, 189.00it/s] 60%|█████▉    | 5375/8973 [00:28<00:19, 189.09it/s] 60%|██████    | 5395/8973 [00:28<00:18, 189.84it/s] 60%|██████    | 5415/8973 [00:28<00:18, 190.15it/s] 61%|██████    | 5435/8973 [00:29<00:18, 189.84it/s] 61%|██████    | 5455/8973 [00:29<00:18, 190.49it/s] 61%|██████    | 5475/8973 [00:29<00:18, 190.41it/s] 61%|██████    | 5495/8973 [00:29<00:18, 190.01it/s] 61%|██████▏   | 5515/8973 [00:29<00:18, 188.41it/s] 62%|██████▏   | 5534/8973 [00:29<00:18, 187.78it/s] 62%|██████▏   | 5554/8973 [00:29<00:18, 188.36it/s] 62%|██████▏   | 5574/8973 [00:29<00:17, 189.33it/s] 62%|██████▏   | 5594/8973 [00:29<00:17, 191.08it/s] 63%|██████▎   | 5614/8973 [00:29<00:17, 190.44it/s] 63%|██████▎   | 5634/8973 [00:30<00:17, 191.05it/s] 63%|██████▎   | 5654/8973 [00:30<00:17, 190.89it/s] 63%|██████▎   | 5674/8973 [00:30<00:17, 189.92it/s] 63%|██████▎   | 5694/8973 [00:30<00:17, 191.31it/s] 64%|██████▎   | 5714/8973 [00:30<00:17, 190.79it/s] 64%|██████▍   | 5734/8973 [00:30<00:16, 191.52it/s] 64%|██████▍   | 5754/8973 [00:30<00:16, 190.28it/s] 64%|██████▍   | 5774/8973 [00:30<00:16, 190.36it/s] 65%|██████▍   | 5794/8973 [00:30<00:16, 189.88it/s] 65%|██████▍   | 5813/8973 [00:31<00:16, 189.89it/s] 65%|██████▍   | 5832/8973 [00:31<00:16, 189.53it/s] 65%|██████▌   | 5851/8973 [00:31<00:16, 189.05it/s] 65%|██████▌   | 5870/8973 [00:31<00:16, 189.11it/s] 66%|██████▌   | 5889/8973 [00:31<00:16, 188.65it/s] 66%|██████▌   | 5908/8973 [00:31<00:16, 188.19it/s] 66%|██████▌   | 5927/8973 [00:31<00:16, 188.29it/s] 66%|██████▋   | 5946/8973 [00:31<00:16, 188.56it/s] 66%|██████▋   | 5965/8973 [00:31<00:15, 188.88it/s] 67%|██████▋   | 5985/8973 [00:31<00:15, 189.97it/s] 67%|██████▋   | 6004/8973 [00:32<00:15, 189.56it/s] 67%|██████▋   | 6023/8973 [00:32<00:15, 188.53it/s] 67%|██████▋   | 6042/8973 [00:32<00:15, 188.96it/s] 68%|██████▊   | 6061/8973 [00:32<00:15, 188.87it/s] 68%|██████▊   | 6080/8973 [00:32<00:15, 188.81it/s] 68%|██████▊   | 6100/8973 [00:32<00:15, 189.71it/s] 68%|██████▊   | 6119/8973 [00:32<00:15, 189.21it/s] 68%|██████▊   | 6138/8973 [00:32<00:15, 188.56it/s] 69%|██████▊   | 6158/8973 [00:32<00:14, 189.05it/s] 69%|██████▉   | 6177/8973 [00:32<00:14, 189.18it/s] 69%|██████▉   | 6197/8973 [00:33<00:14, 189.29it/s] 69%|██████▉   | 6216/8973 [00:33<00:14, 189.21it/s] 69%|██████▉   | 6235/8973 [00:33<00:14, 189.16it/s] 70%|██████▉   | 6254/8973 [00:33<00:14, 188.84it/s] 70%|██████▉   | 6274/8973 [00:33<00:14, 190.36it/s] 70%|███████   | 6294/8973 [00:33<00:14, 190.44it/s] 70%|███████   | 6314/8973 [00:33<00:13, 190.27it/s] 71%|███████   | 6334/8973 [00:33<00:13, 192.39it/s] 71%|███████   | 6354/8973 [00:33<00:13, 192.12it/s] 71%|███████   | 6374/8973 [00:33<00:13, 190.79it/s] 71%|███████▏  | 6394/8973 [00:34<00:13, 190.07it/s] 71%|███████▏  | 6414/8973 [00:34<00:13, 189.32it/s] 72%|███████▏  | 6434/8973 [00:34<00:13, 190.19it/s] 72%|███████▏  | 6454/8973 [00:34<00:13, 189.12it/s] 72%|███████▏  | 6473/8973 [00:34<00:13, 189.18it/s] 72%|███████▏  | 6492/8973 [00:34<00:13, 188.01it/s] 73%|███████▎  | 6511/8973 [00:34<00:13, 187.20it/s] 73%|███████▎  | 6530/8973 [00:34<00:13, 186.02it/s] 73%|███████▎  | 6549/8973 [00:34<00:12, 186.55it/s] 73%|███████▎  | 6568/8973 [00:34<00:12, 186.38it/s] 73%|███████▎  | 6587/8973 [00:35<00:12, 186.40it/s] 74%|███████▎  | 6606/8973 [00:35<00:12, 186.29it/s] 74%|███████▍  | 6625/8973 [00:35<00:12, 186.34it/s] 74%|███████▍  | 6644/8973 [00:35<00:12, 187.09it/s] 74%|███████▍  | 6663/8973 [00:35<00:12, 187.13it/s] 74%|███████▍  | 6683/8973 [00:35<00:12, 188.91it/s] 75%|███████▍  | 6702/8973 [00:35<00:12, 188.21it/s] 75%|███████▍  | 6722/8973 [00:35<00:11, 189.67it/s] 75%|███████▌  | 6741/8973 [00:35<00:11, 188.87it/s] 75%|███████▌  | 6761/8973 [00:36<00:11, 190.63it/s] 76%|███████▌  | 6781/8973 [00:36<00:11, 189.71it/s] 76%|███████▌  | 6801/8973 [00:36<00:11, 189.87it/s] 76%|███████▌  | 6821/8973 [00:36<00:11, 190.48it/s] 76%|███████▌  | 6841/8973 [00:36<00:11, 190.38it/s] 76%|███████▋  | 6861/8973 [00:36<00:11, 189.85it/s] 77%|███████▋  | 6880/8973 [00:36<00:11, 189.60it/s] 77%|███████▋  | 6900/8973 [00:36<00:10, 189.73it/s] 77%|███████▋  | 6920/8973 [00:36<00:10, 190.92it/s] 77%|███████▋  | 6940/8973 [00:36<00:10, 190.26it/s] 78%|███████▊  | 6960/8973 [00:37<00:10, 191.22it/s] 78%|███████▊  | 6980/8973 [00:37<00:10, 191.39it/s] 78%|███████▊  | 7000/8973 [00:37<00:10, 192.59it/s] 78%|███████▊  | 7020/8973 [00:37<00:10, 192.01it/s] 78%|███████▊  | 7040/8973 [00:37<00:10, 190.66it/s] 79%|███████▊  | 7060/8973 [00:37<00:10, 190.48it/s] 79%|███████▉  | 7080/8973 [00:37<00:09, 191.73it/s] 79%|███████▉  | 7100/8973 [00:37<00:09, 191.11it/s] 79%|███████▉  | 7120/8973 [00:37<00:09, 191.34it/s] 80%|███████▉  | 7140/8973 [00:38<00:09, 192.51it/s] 80%|███████▉  | 7160/8973 [00:38<00:09, 192.41it/s] 80%|████████  | 7180/8973 [00:38<00:09, 191.92it/s] 80%|████████  | 7200/8973 [00:38<00:09, 192.09it/s] 80%|████████  | 7220/8973 [00:38<00:09, 192.07it/s] 81%|████████  | 7240/8973 [00:38<00:09, 191.57it/s] 81%|████████  | 7260/8973 [00:38<00:08, 190.39it/s] 81%|████████  | 7280/8973 [00:38<00:08, 190.62it/s] 81%|████████▏ | 7300/8973 [00:38<00:08, 189.21it/s] 82%|████████▏ | 7320/8973 [00:38<00:08, 189.90it/s] 82%|████████▏ | 7340/8973 [00:39<00:08, 190.11it/s] 82%|████████▏ | 7360/8973 [00:39<00:08, 189.31it/s] 82%|████████▏ | 7380/8973 [00:39<00:08, 189.42it/s] 82%|████████▏ | 7400/8973 [00:39<00:08, 189.62it/s] 83%|████████▎ | 7419/8973 [00:39<00:08, 189.31it/s] 83%|████████▎ | 7438/8973 [00:39<00:08, 188.98it/s] 83%|████████▎ | 7458/8973 [00:39<00:07, 190.07it/s] 83%|████████▎ | 7478/8973 [00:39<00:07, 189.74it/s] 84%|████████▎ | 7498/8973 [00:39<00:07, 191.91it/s] 84%|████████▍ | 7518/8973 [00:39<00:07, 191.68it/s] 84%|████████▍ | 7538/8973 [00:40<00:07, 190.44it/s] 84%|████████▍ | 7558/8973 [00:40<00:07, 190.69it/s] 84%|████████▍ | 7578/8973 [00:40<00:07, 191.30it/s] 85%|████████▍ | 7598/8973 [00:40<00:07, 191.16it/s] 85%|████████▍ | 7618/8973 [00:40<00:07, 191.12it/s] 85%|████████▌ | 7638/8973 [00:40<00:06, 192.14it/s] 85%|████████▌ | 7658/8973 [00:40<00:06, 191.21it/s] 86%|████████▌ | 7678/8973 [00:40<00:06, 190.48it/s] 86%|████████▌ | 7698/8973 [00:40<00:06, 190.33it/s] 86%|████████▌ | 7718/8973 [00:41<00:06, 189.82it/s] 86%|████████▌ | 7737/8973 [00:41<00:06, 189.72it/s] 86%|████████▋ | 7757/8973 [00:41<00:06, 189.83it/s] 87%|████████▋ | 7776/8973 [00:41<00:06, 189.87it/s] 87%|████████▋ | 7795/8973 [00:41<00:06, 188.85it/s] 87%|████████▋ | 7814/8973 [00:41<00:06, 188.16it/s] 87%|████████▋ | 7834/8973 [00:41<00:06, 188.91it/s] 88%|████████▊ | 7854/8973 [00:41<00:05, 190.01it/s] 88%|████████▊ | 7874/8973 [00:41<00:05, 190.14it/s] 88%|████████▊ | 7894/8973 [00:41<00:05, 189.82it/s] 88%|████████▊ | 7913/8973 [00:42<00:05, 189.67it/s] 88%|████████▊ | 7932/8973 [00:42<00:05, 188.76it/s] 89%|████████▊ | 7951/8973 [00:42<00:05, 188.33it/s] 89%|████████▉ | 7971/8973 [00:42<00:05, 189.36it/s] 89%|████████▉ | 7991/8973 [00:42<00:05, 189.96it/s] 89%|████████▉ | 8011/8973 [00:42<00:05, 190.79it/s] 90%|████████▉ | 8031/8973 [00:42<00:04, 189.75it/s] 90%|████████▉ | 8050/8973 [00:42<00:04, 188.53it/s] 90%|████████▉ | 8069/8973 [00:42<00:04, 188.52it/s] 90%|█████████ | 8088/8973 [00:42<00:04, 188.07it/s] 90%|█████████ | 8107/8973 [00:43<00:04, 188.02it/s] 91%|█████████ | 8126/8973 [00:43<00:04, 187.10it/s] 91%|█████████ | 8145/8973 [00:43<00:04, 187.83it/s] 91%|█████████ | 8165/8973 [00:43<00:04, 188.50it/s] 91%|█████████ | 8184/8973 [00:43<00:04, 187.80it/s] 91%|█████████▏| 8203/8973 [00:43<00:04, 186.40it/s] 92%|█████████▏| 8222/8973 [00:43<00:04, 186.21it/s] 92%|█████████▏| 8242/8973 [00:43<00:03, 187.68it/s] 92%|█████████▏| 8261/8973 [00:43<00:03, 188.25it/s] 92%|█████████▏| 8280/8973 [00:44<00:03, 178.41it/s] 92%|█████████▏| 8299/8973 [00:44<00:03, 180.82it/s] 93%|█████████▎| 8318/8973 [00:44<00:03, 181.67it/s] 93%|█████████▎| 8337/8973 [00:44<00:03, 179.60it/s] 93%|█████████▎| 8357/8973 [00:44<00:03, 185.37it/s] 93%|█████████▎| 8376/8973 [00:44<00:03, 186.19it/s] 94%|█████████▎| 8396/8973 [00:44<00:03, 187.83it/s] 94%|█████████▍| 8415/8973 [00:44<00:02, 187.80it/s] 94%|█████████▍| 8435/8973 [00:44<00:02, 188.80it/s] 94%|█████████▍| 8455/8973 [00:44<00:02, 189.42it/s] 94%|█████████▍| 8475/8973 [00:45<00:02, 189.48it/s] 95%|█████████▍| 8495/8973 [00:45<00:02, 190.32it/s] 95%|█████████▍| 8515/8973 [00:45<00:02, 190.40it/s] 95%|█████████▌| 8535/8973 [00:45<00:02, 190.09it/s] 95%|█████████▌| 8555/8973 [00:45<00:02, 189.27it/s] 96%|█████████▌| 8575/8973 [00:45<00:02, 190.00it/s] 96%|█████████▌| 8595/8973 [00:45<00:01, 190.18it/s] 96%|█████████▌| 8615/8973 [00:45<00:01, 189.97it/s] 96%|█████████▌| 8635/8973 [00:45<00:01, 191.26it/s] 96%|█████████▋| 8655/8973 [00:46<00:01, 190.01it/s] 97%|█████████▋| 8675/8973 [00:46<00:01, 190.09it/s] 97%|█████████▋| 8695/8973 [00:46<00:01, 190.57it/s] 97%|█████████▋| 8715/8973 [00:46<00:01, 190.48it/s] 97%|█████████▋| 8735/8973 [00:46<00:01, 189.95it/s] 98%|█████████▊| 8754/8973 [00:46<00:01, 189.96it/s] 98%|█████████▊| 8774/8973 [00:46<00:01, 190.09it/s] 98%|█████████▊| 8794/8973 [00:46<00:00, 190.72it/s] 98%|█████████▊| 8814/8973 [00:46<00:00, 190.71it/s] 98%|█████████▊| 8834/8973 [00:46<00:00, 190.47it/s] 99%|█████████▊| 8854/8973 [00:47<00:00, 190.51it/s] 99%|█████████▉| 8874/8973 [00:47<00:00, 189.81it/s] 99%|█████████▉| 8894/8973 [00:47<00:00, 191.32it/s] 99%|█████████▉| 8914/8973 [00:47<00:00, 190.61it/s]100%|█████████▉| 8934/8973 [00:47<00:00, 190.87it/s]100%|█████████▉| 8954/8973 [00:47<00:00, 190.83it/s]100%|██████████| 8973/8973 [00:47<00:00, 188.15it/s]
  0%|          | 0/3846 [00:00<?, ?it/s]  1%|          | 25/3846 [00:00<00:15, 249.07it/s]  1%|▏         | 51/3846 [00:00<00:15, 249.86it/s]  2%|▏         | 76/3846 [00:00<00:15, 248.66it/s]  3%|▎         | 101/3846 [00:00<00:15, 247.56it/s]  3%|▎         | 126/3846 [00:00<00:15, 247.41it/s]  4%|▍         | 151/3846 [00:00<00:15, 246.05it/s]  5%|▍         | 177/3846 [00:00<00:14, 247.91it/s]  5%|▌         | 202/3846 [00:00<00:14, 248.02it/s]  6%|▌         | 227/3846 [00:00<00:14, 246.57it/s]  7%|▋         | 252/3846 [00:01<00:14, 246.47it/s]  7%|▋         | 277/3846 [00:01<00:14, 247.13it/s]  8%|▊         | 302/3846 [00:01<00:14, 247.02it/s]  9%|▊         | 327/3846 [00:01<00:14, 246.41it/s]  9%|▉         | 352/3846 [00:01<00:14, 247.34it/s] 10%|▉         | 377/3846 [00:01<00:14, 247.50it/s] 10%|█         | 403/3846 [00:01<00:13, 248.10it/s] 11%|█         | 428/3846 [00:01<00:13, 247.95it/s] 12%|█▏        | 453/3846 [00:01<00:13, 247.78it/s] 12%|█▏        | 478/3846 [00:01<00:13, 247.37it/s] 13%|█▎        | 503/3846 [00:02<00:13, 247.73it/s] 14%|█▎        | 528/3846 [00:02<00:13, 246.35it/s] 14%|█▍        | 554/3846 [00:02<00:13, 248.36it/s] 15%|█▌        | 579/3846 [00:02<00:13, 247.41it/s] 16%|█▌        | 605/3846 [00:02<00:13, 248.11it/s] 16%|█▋        | 630/3846 [00:02<00:12, 247.49it/s] 17%|█▋        | 656/3846 [00:02<00:12, 249.29it/s] 18%|█▊        | 681/3846 [00:02<00:12, 249.23it/s] 18%|█▊        | 706/3846 [00:02<00:12, 248.91it/s] 19%|█▉        | 731/3846 [00:02<00:12, 248.69it/s] 20%|█▉        | 756/3846 [00:03<00:12, 248.94it/s] 20%|██        | 782/3846 [00:03<00:12, 249.60it/s] 21%|██        | 807/3846 [00:03<00:12, 249.28it/s] 22%|██▏       | 832/3846 [00:03<00:12, 249.12it/s] 22%|██▏       | 858/3846 [00:03<00:11, 250.37it/s] 23%|██▎       | 884/3846 [00:03<00:11, 250.38it/s] 24%|██▎       | 910/3846 [00:03<00:11, 248.49it/s] 24%|██▍       | 935/3846 [00:03<00:11, 248.45it/s] 25%|██▍       | 960/3846 [00:03<00:11, 247.29it/s] 26%|██▌       | 985/3846 [00:03<00:11, 246.87it/s] 26%|██▋       | 1010/3846 [00:04<00:11, 247.13it/s] 27%|██▋       | 1035/3846 [00:04<00:11, 244.88it/s] 28%|██▊       | 1061/3846 [00:04<00:11, 248.39it/s] 28%|██▊       | 1086/3846 [00:04<00:11, 248.79it/s] 29%|██▉       | 1111/3846 [00:04<00:10, 248.91it/s] 30%|██▉       | 1136/3846 [00:04<00:10, 248.52it/s] 30%|███       | 1162/3846 [00:04<00:10, 249.43it/s] 31%|███       | 1187/3846 [00:04<00:10, 247.89it/s] 32%|███▏      | 1212/3846 [00:04<00:10, 248.30it/s] 32%|███▏      | 1238/3846 [00:04<00:10, 249.35it/s] 33%|███▎      | 1263/3846 [00:05<00:10, 248.86it/s] 33%|███▎      | 1288/3846 [00:05<00:10, 247.55it/s] 34%|███▍      | 1313/3846 [00:05<00:10, 246.74it/s] 35%|███▍      | 1338/3846 [00:05<00:10, 245.03it/s] 35%|███▌      | 1364/3846 [00:05<00:10, 247.30it/s] 36%|███▌      | 1389/3846 [00:05<00:09, 247.86it/s] 37%|███▋      | 1414/3846 [00:05<00:09, 246.68it/s] 37%|███▋      | 1439/3846 [00:05<00:09, 246.63it/s] 38%|███▊      | 1464/3846 [00:05<00:09, 245.67it/s] 39%|███▊      | 1489/3846 [00:06<00:09, 246.77it/s] 39%|███▉      | 1514/3846 [00:06<00:09, 245.74it/s] 40%|████      | 1539/3846 [00:06<00:09, 245.15it/s] 41%|████      | 1564/3846 [00:06<00:09, 244.65it/s] 41%|████▏     | 1589/3846 [00:06<00:09, 245.73it/s] 42%|████▏     | 1614/3846 [00:06<00:09, 246.58it/s] 43%|████▎     | 1639/3846 [00:06<00:08, 246.05it/s] 43%|████▎     | 1665/3846 [00:06<00:08, 247.21it/s] 44%|████▍     | 1690/3846 [00:06<00:08, 243.69it/s] 45%|████▍     | 1715/3846 [00:06<00:09, 233.95it/s] 45%|████▌     | 1741/3846 [00:07<00:08, 239.92it/s] 46%|████▌     | 1766/3846 [00:07<00:08, 240.73it/s] 47%|████▋     | 1791/3846 [00:07<00:08, 241.73it/s] 47%|████▋     | 1816/3846 [00:07<00:08, 240.16it/s] 48%|████▊     | 1842/3846 [00:07<00:08, 243.99it/s] 49%|████▊     | 1867/3846 [00:07<00:08, 242.33it/s] 49%|████▉     | 1892/3846 [00:07<00:08, 241.78it/s] 50%|████▉     | 1917/3846 [00:07<00:08, 240.76it/s] 50%|█████     | 1942/3846 [00:07<00:07, 241.66it/s] 51%|█████     | 1967/3846 [00:07<00:07, 242.04it/s] 52%|█████▏    | 1992/3846 [00:08<00:07, 241.77it/s] 52%|█████▏    | 2017/3846 [00:08<00:07, 241.03it/s] 53%|█████▎    | 2042/3846 [00:08<00:07, 241.65it/s] 54%|█████▎    | 2067/3846 [00:08<00:07, 241.43it/s] 54%|█████▍    | 2093/3846 [00:08<00:07, 244.61it/s] 55%|█████▌    | 2118/3846 [00:08<00:07, 245.37it/s] 56%|█████▌    | 2143/3846 [00:08<00:07, 226.70it/s] 56%|█████▋    | 2167/3846 [00:08<00:07, 228.10it/s] 57%|█████▋    | 2192/3846 [00:08<00:07, 234.21it/s] 58%|█████▊    | 2216/3846 [00:09<00:06, 233.60it/s] 58%|█████▊    | 2241/3846 [00:09<00:06, 237.93it/s] 59%|█████▉    | 2266/3846 [00:09<00:06, 240.09it/s] 60%|█████▉    | 2291/3846 [00:09<00:06, 240.74it/s] 60%|██████    | 2316/3846 [00:09<00:06, 242.77it/s] 61%|██████    | 2341/3846 [00:09<00:06, 243.14it/s] 62%|██████▏   | 2366/3846 [00:09<00:06, 244.01it/s] 62%|██████▏   | 2391/3846 [00:09<00:05, 245.05it/s] 63%|██████▎   | 2416/3846 [00:09<00:05, 244.29it/s] 63%|██████▎   | 2441/3846 [00:09<00:05, 245.40it/s] 64%|██████▍   | 2467/3846 [00:10<00:05, 247.24it/s] 65%|██████▍   | 2492/3846 [00:10<00:05, 246.81it/s] 65%|██████▌   | 2517/3846 [00:10<00:05, 245.85it/s] 66%|██████▌   | 2542/3846 [00:10<00:05, 245.99it/s] 67%|██████▋   | 2567/3846 [00:10<00:05, 246.77it/s] 67%|██████▋   | 2592/3846 [00:10<00:05, 247.70it/s] 68%|██████▊   | 2618/3846 [00:10<00:04, 248.63it/s] 69%|██████▊   | 2643/3846 [00:10<00:04, 248.07it/s] 69%|██████▉   | 2668/3846 [00:10<00:04, 246.84it/s] 70%|███████   | 2693/3846 [00:10<00:04, 244.78it/s] 71%|███████   | 2718/3846 [00:11<00:04, 246.04it/s] 71%|███████▏  | 2743/3846 [00:11<00:04, 246.56it/s] 72%|███████▏  | 2768/3846 [00:11<00:04, 244.87it/s] 73%|███████▎  | 2793/3846 [00:11<00:04, 245.90it/s] 73%|███████▎  | 2818/3846 [00:11<00:04, 246.60it/s] 74%|███████▍  | 2843/3846 [00:11<00:04, 246.44it/s] 75%|███████▍  | 2869/3846 [00:11<00:03, 248.20it/s] 75%|███████▌  | 2894/3846 [00:11<00:03, 247.17it/s] 76%|███████▌  | 2919/3846 [00:11<00:03, 244.53it/s] 77%|███████▋  | 2944/3846 [00:11<00:03, 245.16it/s] 77%|███████▋  | 2970/3846 [00:12<00:03, 246.88it/s] 78%|███████▊  | 2995/3846 [00:12<00:03, 246.47it/s] 79%|███████▊  | 3020/3846 [00:12<00:03, 246.19it/s] 79%|███████▉  | 3046/3846 [00:12<00:03, 247.57it/s] 80%|███████▉  | 3071/3846 [00:12<00:03, 247.91it/s] 80%|████████  | 3096/3846 [00:12<00:03, 245.96it/s] 81%|████████  | 3121/3846 [00:12<00:02, 246.03it/s] 82%|████████▏ | 3146/3846 [00:12<00:02, 246.66it/s] 82%|████████▏ | 3171/3846 [00:12<00:02, 247.23it/s] 83%|████████▎ | 3196/3846 [00:13<00:02, 247.23it/s] 84%|████████▎ | 3221/3846 [00:13<00:02, 247.00it/s] 84%|████████▍ | 3246/3846 [00:13<00:02, 246.13it/s] 85%|████████▌ | 3271/3846 [00:13<00:02, 246.97it/s] 86%|████████▌ | 3296/3846 [00:13<00:02, 247.59it/s] 86%|████████▋ | 3321/3846 [00:13<00:02, 246.09it/s] 87%|████████▋ | 3346/3846 [00:13<00:02, 245.81it/s] 88%|████████▊ | 3371/3846 [00:13<00:01, 245.65it/s] 88%|████████▊ | 3396/3846 [00:13<00:01, 245.49it/s] 89%|████████▉ | 3421/3846 [00:13<00:01, 245.17it/s] 90%|████████▉ | 3446/3846 [00:14<00:01, 242.95it/s] 90%|█████████ | 3471/3846 [00:14<00:01, 243.01it/s] 91%|█████████ | 3496/3846 [00:14<00:01, 242.32it/s] 92%|█████████▏| 3522/3846 [00:14<00:01, 244.54it/s] 92%|█████████▏| 3547/3846 [00:14<00:01, 243.63it/s] 93%|█████████▎| 3572/3846 [00:14<00:01, 243.10it/s] 94%|█████████▎| 3597/3846 [00:14<00:01, 243.92it/s] 94%|█████████▍| 3622/3846 [00:14<00:00, 244.42it/s] 95%|█████████▍| 3647/3846 [00:14<00:00, 244.59it/s] 95%|█████████▌| 3672/3846 [00:14<00:00, 244.78it/s] 96%|█████████▌| 3697/3846 [00:15<00:00, 245.09it/s] 97%|█████████▋| 3723/3846 [00:15<00:00, 248.69it/s] 97%|█████████▋| 3748/3846 [00:15<00:00, 248.51it/s] 98%|█████████▊| 3773/3846 [00:15<00:00, 246.44it/s] 99%|█████████▉| 3798/3846 [00:15<00:00, 247.04it/s] 99%|█████████▉| 3824/3846 [00:15<00:00, 249.87it/s]100%|██████████| 3846/3846 [00:15<00:00, 245.63it/s]
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1716299082.672574 1203021 service.cc:145] XLA service 0x7fbc88124380 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1716299082.672928 1203021 service.cc:153]   StreamExecutor device (0): NVIDIA H100 PCIe, Compute Capability 9.0
2024-05-21 15:44:44.694239: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-05-21 15:44:51.075022: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1716299120.326312 1203021 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_261', 64 bytes spill stores, 64 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_259', 320 bytes spill stores, 320 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_219', 320 bytes spill stores, 320 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_214', 1112 bytes spill stores, 1108 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_211', 320 bytes spill stores, 320 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_208', 1112 bytes spill stores, 1108 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_198', 64 bytes spill stores, 64 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_145', 1112 bytes spill stores, 1108 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_81', 320 bytes spill stores, 320 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_144', 320 bytes spill stores, 320 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_143', 352 bytes spill stores, 352 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_142', 876 bytes spill stores, 860 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_9', 352 bytes spill stores, 352 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_6', 876 bytes spill stores, 860 bytes spill loads

I0000 00:00:1716299120.408148 1203021 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2024-05-21 15:47:42.385276: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
I0000 00:00:1716299296.951132 1203021 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_30', 64 bytes spill stores, 64 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_47', 320 bytes spill stores, 320 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_46', 1112 bytes spill stores, 1108 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_37', 320 bytes spill stores, 320 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_18', 320 bytes spill stores, 320 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_34', 1112 bytes spill stores, 1108 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_33', 320 bytes spill stores, 320 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_32', 1112 bytes spill stores, 1108 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_13', 1112 bytes spill stores, 1108 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_12', 320 bytes spill stores, 320 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_89', 64 bytes spill stores, 64 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_75', 320 bytes spill stores, 320 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_74', 1112 bytes spill stores, 1108 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_72', 1112 bytes spill stores, 1108 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_71', 320 bytes spill stores, 320 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_70', 876 bytes spill stores, 860 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion', 352 bytes spill stores, 352 bytes spill loads

2024-05-21 15:48:19.563395: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 15:48:19.799611: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 15:50:43.096061: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 15:50:44.458776: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 15:50:44.695764: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 15:53:08.088429: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 15:53:09.490419: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 15:53:09.744591: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 15:55:33.232588: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 15:55:34.438646: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 15:55:34.615117: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 15:57:57.968378: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 15:57:59.215306: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 15:57:59.428817: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:00:22.907650: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:00:24.235685: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:00:24.485653: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:02:47.929791: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:02:49.302065: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:02:49.557546: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:05:12.795686: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:05:14.152665: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:05:14.412824: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:07:37.775509: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:07:39.140321: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:07:39.372091: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:10:02.616078: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:10:03.958455: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:10:04.193068: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:12:27.323128: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:12:28.632894: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:12:28.884461: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:14:52.119595: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:14:53.460313: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:14:53.690136: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:17:16.895970: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:17:18.242392: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:17:18.493671: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:19:41.682745: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:19:43.080894: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:19:43.346372: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:22:06.463912: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:22:08.659063: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:22:08.924521: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:24:32.003301: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:24:33.358484: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:24:33.606341: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:26:56.745695: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:26:58.085572: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:26:58.340846: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:29:21.306355: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:29:22.695196: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:29:22.956412: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:31:45.987339: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:31:47.392305: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:31:47.660260: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:34:10.650979: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:34:12.020677: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:34:12.273290: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:36:35.191587: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:36:36.570040: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:36:36.814883: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:38:59.912719: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:39:01.223510: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:39:01.472002: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:41:24.375557: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:41:25.827721: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:41:26.099183: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:43:49.143843: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:43:50.486420: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:43:50.731355: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:46:13.719880: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:46:15.094810: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:46:15.362647: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:48:38.195747: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:48:39.472048: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:48:39.700076: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:51:02.444561: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:51:03.811691: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:51:04.029631: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:53:26.683463: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:53:28.049886: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:53:28.306557: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:55:50.917243: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:55:52.229576: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:55:52.459728: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 16:58:15.147476: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:58:16.554601: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 16:58:16.790046: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:00:39.341996: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:00:41.520500: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:00:41.788778: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:03:04.451928: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:03:05.811981: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:03:06.054887: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:05:28.766873: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:05:30.127381: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:05:30.346497: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:07:52.916513: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:07:54.253670: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:07:54.473801: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:10:17.045193: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:10:18.436387: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:10:18.670219: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:12:41.236861: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:12:42.525767: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:12:42.740330: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:15:05.202396: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:15:06.518976: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:15:06.780712: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:17:29.326097: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:17:30.671209: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:17:30.920024: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:19:53.383284: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:19:54.745336: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:19:54.981268: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:22:17.647469: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:22:18.955737: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:22:19.190017: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:24:41.697216: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:24:43.063293: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:24:43.314853: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:27:05.727079: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:27:07.090086: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:27:07.351240: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:29:29.930531: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:29:31.288263: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:29:31.553407: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:31:54.198307: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:31:55.547285: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:31:55.799262: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:34:18.245828: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:34:19.640375: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:34:19.899596: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:36:42.402187: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:36:43.790267: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:36:44.049144: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:39:06.345582: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:39:08.522737: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:39:08.779697: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:41:31.175148: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:41:32.458313: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:41:32.709877: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:43:55.100308: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:43:56.485285: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:43:56.763845: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
2024-05-21 17:46:19.054530: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:46:20.436046: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-05-21 17:46:20.688927: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
